{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on_kaggle = True\n",
    "on_kaggle = False\n",
    "\n",
    "#TRAIN_PREDICT = 'predict'\n",
    "TRAIN_PREDICT = 'train'\n",
    "\n",
    "if not on_kaggle:\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "import random\n",
    "\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "#import gensim\n",
    "#import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "#fix bug with using CuDNNLSTM\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "\n",
    "#from transformers import *\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    #torch.manual_seed(seed)\n",
    "    #torch.cuda.manual_seed_all(seed)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    tf.random.set_seed(seed)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape = (6079, 41)\n",
      "test shape = (476, 11)\n",
      "\n",
      "output categories:\n",
      "\t ['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n",
      "\n",
      "input categories:\n",
      "\t ['question_title', 'question_body', 'answer', 'category', 'host']\n"
     ]
    }
   ],
   "source": [
    "if on_kaggle:\n",
    "    PATH = '../input/google-quest-challenge/'\n",
    "    CKPT_LOAD_PATH = ['../input/google-quest-qa-labeling-checkpoints/fold0-epoch3.h5py']\n",
    "else:##offline\n",
    "    PATH = '../data/'\n",
    "    CKPT_SAVE_PATH = '../checkpoint/use-v1/'\n",
    "    #CKPT_LOAD_PATH = ['../checkpoint/bert-base-uncased/']\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "df_train = pd.read_csv(PATH+'train.csv')\n",
    "df_test = pd.read_csv(PATH+'test.csv')\n",
    "df_sub = pd.read_csv(PATH+'sample_submission.csv')\n",
    "print('train shape =', df_train.shape)\n",
    "print('test shape =', df_test.shape)\n",
    "\n",
    "output_categories = list(df_train.columns[11:])\n",
    "input_categories = list(df_train.columns[[1,2,5,9,10]])#9:category, 10:host\n",
    "print('\\noutput categories:\\n\\t', output_categories)\n",
    "print('\\ninput categories:\\n\\t', input_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read USE sentence embedding model\n",
    "#embeddings.shape==[1, 512]\n",
    "if on_kaggle:\n",
    "    pass\n",
    "else:\n",
    "    os.environ[\"TFHUB_CACHE_DIR\"]=\"../data/\"\n",
    "    #use_embed = hub.load(\"https://hub.tensorflow.google.cn/google/universal-sentence-encoder-large/5\")\n",
    "    use_embed = hub.KerasLayer(handle=\"https://hub.tensorflow.google.cn/google/universal-sentence-encoder-large/5\", \n",
    "                               trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load() #nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# qss, ass = [], []\n",
    "# for i,row in tqdm(df_train.iterrows()):\n",
    "#     if i not in list(range(100,200)):\n",
    "#         continue\n",
    "    \n",
    "#     #single sample\n",
    "#     t,q,a = row['question_title'],row['question_body'],row['answer']\n",
    "#     ##for question text\n",
    "#     doc_q = nlp(t+' '+q)\n",
    "#     sentences_q = [sent.string.strip() for sent in doc_q.sents]\n",
    "#     #print('[question]number of sentences: ', len(sentences_q))\n",
    "#     out = []\n",
    "#     #use 8 passages\n",
    "#     ns = len(sentences_q)//8 #8 passages, ns sentences each passage\n",
    "#     if ns==0:\n",
    "#         ns = 1\n",
    "#     for j in range(8):\n",
    "#         p = ' '.join(s for s in sentences_q[ns*j:ns*(j+1)])\n",
    "#         if j==7:\n",
    "#             p += ' '.join(s for s in sentences_q[ns*(j+1):])\n",
    "#         #print(j, p)\n",
    "#         #out.append(use_embed([p])[0])\n",
    "#         out.append(p)\n",
    "#     #out = np.array(out).T\n",
    "#     qss.append(out)\n",
    "#     ##for answer text\n",
    "#     doc_a = nlp(a)\n",
    "#     sentences_a = [sent.string.strip() for sent in doc_a.sents]\n",
    "#     #print('[answer]number of sentences: ', len(sentences_a))\n",
    "#     out = []\n",
    "#     #use 8 passages\n",
    "#     ns = len(sentences_a)//8 #8 passages, ns sentences each passage\n",
    "#     if ns==0:\n",
    "#         ns = 1\n",
    "#     for j in range(8):\n",
    "#         p = ' '.join(s for s in sentences_a[ns*j:ns*(j+1)])\n",
    "#         if j==7:\n",
    "#             p += ' '.join(s for s in sentences_a[ns*(j+1):])\n",
    "#         #print(j, p)\n",
    "#         #out.append(use_embed([p])[0])\n",
    "#         out.append(p)\n",
    "#     #out = np.array(out).T\n",
    "#     ass.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##text cleaning 1\n",
    "import html\n",
    "for col in ['question_title', 'question_body', 'answer']:\n",
    "    df_train[col] = df_train[col].apply(html.unescape)\n",
    "    df_test[col] = df_test[col].apply(html.unescape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def slide_window_sentence(text):\n",
    "#     \"\"\"text: raw text full\n",
    "    \n",
    "#     return: list of string(sentence), ['sentence 1', ..., 'sentence N']\n",
    "#     \"\"\"\n",
    "#     tokens = tokenizer.encode_plus(text, None, \n",
    "#                                add_special_tokens=True, max_length=None, \n",
    "#                                truncation_strategy='longest_first')\n",
    "#     a = tokens['input_ids']\n",
    "    \n",
    "#     t_len = len(a)\n",
    "#     s_len = 8 #sentence/window length\n",
    "#     overlap = 3 #how many words overlap\n",
    "#     num_sentence = 512 #max number of sentences, if padding or truncate\n",
    "#     #print(t_len, s_len)\n",
    "#     sentences = []\n",
    "#     i = 0\n",
    "#     while True:\n",
    "#         if i==0:\n",
    "#             #print(a[0:s_len])\n",
    "#             sentence = tokenizer.decode(a[0:s_len], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "#         else:\n",
    "#             #print(a[i*s_len-overlap*i:(i+1)*s_len-overlap*i])\n",
    "#             sentence = tokenizer.decode(a[i*s_len-overlap*i:(i+1)*s_len-overlap*i], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "#         sentences.append(sentence)\n",
    "#         i += 1\n",
    "#         if i*s_len-overlap*i>t_len:\n",
    "#             break\n",
    "#     if len(sentences)<num_sentence:\n",
    "#         to_pad = ['']*(num_sentence-len(sentences))\n",
    "#         sentences.extend(to_pad)\n",
    "#     else:\n",
    "#         sentences = sentences[:num_sentence]\n",
    "#     #return sentences\n",
    "#     return use_embed(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# idx = 1\n",
    "# t,q,a = df_train.loc[idx, 'question_title'], df_train.loc[idx, 'question_body'], df_train.loc[idx, 'answer']\n",
    "# print(t+' '+q+'\\n'+'='*40+'\\n'+a+'='*40)\n",
    "\n",
    "# tokens = tokenizer.encode_plus(t+' '+q, None, \n",
    "#                                add_special_tokens=True, \n",
    "#                                max_length=None, \n",
    "#                                truncation_strategy='longest_first')\n",
    "# print([tokenizer.ids_to_tokens[i] for i in tokens['input_ids']])\n",
    "#print(' '.join(tokenizer.ids_to_tokens[i] for i in tokens['input_ids']))\n",
    "\n",
    "# # #sentences = slide_window_sentence([2054]*6)\n",
    "# # sentences = slide_window_sentence(tokens['input_ids'])\n",
    "# # print(len(sentences))\n",
    "# # sentences\n",
    "\n",
    "# def slide_window(tokens, max_seq_len=384, doc_stride=128, cnt_sentence=16):\n",
    "#     \"\"\"\n",
    "#     text: raw str, t+q+a\n",
    "#     \"\"\"\n",
    "#     output = []\n",
    "#     start_pos = 0\n",
    "#     end_pos = -1\n",
    "#     sentence_cnt = 0\n",
    "#     all_tokens_len = len(tokens)\n",
    "#     if start_pos<all_tokens_len:\n",
    "#         if start_pos+max_seq_len>all_tokens_len:\n",
    "#             seq = tokens[start_pos:]\n",
    "            \n",
    "    \n",
    "#     return None\n",
    "\n",
    "# print(len(tokens['input_ids']))\n",
    "# slide_window(tokens['input_ids'], max_seq_len=384, doc_stride=128, cnt_sentence=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_special_char(x):\n",
    "    special_character = re.compile(r'[^A-Za-z\\.\\-\\?\\!\\,\\#\\@\\% ]', re.IGNORECASE)\n",
    "    x_ascii = unidecode(x)\n",
    "    s = special_character.findall(x_ascii)\n",
    "    #print(s)\n",
    "    c = len(s)\n",
    "    return c\n",
    "\n",
    "def count_cap_char(x):\n",
    "    c = sum(1 for l in x if l.isupper())\n",
    "    return c\n",
    "\n",
    "def count_unique_words(x):\n",
    "    \"\"\"returns a ratio\"\"\"\n",
    "    special_character = re.compile(r'[^A-Za-z0-9]', re.IGNORECASE)\n",
    "    a = [w for w in special_character.split(x) if w!='']\n",
    "    r = len(set(a))/len(a)\n",
    "    return r\n",
    "\n",
    "#print(t)\n",
    "#count_cap_char(t), len(t)\n",
    "#count_special_char(t), len(t)\n",
    "#string.printable\n",
    "\n",
    "#from textblob import TextBlob\n",
    "# print(t.lower())\n",
    "# print('='*40)\n",
    "# print(TextBlob(t.lower()).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIFE_ARTS': 1,\n",
       " 'CULTURE': 2,\n",
       " 'SCIENCE': 3,\n",
       " 'STACKOVERFLOW': 4,\n",
       " 'TECHNOLOGY': 5,\n",
       " 'UNK': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = df_train.category.unique().tolist()\n",
    "category2index = dict([(l[i],i+1) for i in range(len(l))])\n",
    "category2index['UNK'] = 0\n",
    "\n",
    "l = df_train.host.unique().tolist()\n",
    "host2index = dict([(l[i],i+1) for i in range(len(l))])\n",
    "host2index['UNK'] = 0\n",
    "\n",
    "category2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
    "    special_char_q, special_char_a = [], []\n",
    "    cap_char_q, cap_char_a = [], []\n",
    "    unique_words_q, unique_words_a = [], []\n",
    "    category_index, host_index = [], []\n",
    "    qss, ass = [], []\n",
    "    for row_id, instance in tqdm(df[columns].iterrows()):\n",
    "        #if row_id>100:\n",
    "        #    break\n",
    "        t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "        \n",
    "        special_char_q.append(count_special_char(t+q)/len(t+q))\n",
    "        special_char_a.append(count_special_char(a)/len(a))\n",
    "        cap_char_q.append(count_cap_char(t+q)/len(t+q))\n",
    "        cap_char_a.append(count_cap_char(a)/len(a))\n",
    "        unique_words_q.append(count_unique_words(t+q))\n",
    "        unique_words_a.append(count_unique_words(a))\n",
    "        \n",
    "        category, host = instance.category, instance.host\n",
    "        category_index.append([category2index.get(category, 0)])\n",
    "        host_index.append([host2index.get(host, 0)])\n",
    "        \n",
    "        ##USE model input \"passages\"\n",
    "        ##for question text\n",
    "        doc_q = nlp(t+' '+q)\n",
    "        sentences_q = [sent.string.strip() for sent in doc_q.sents]\n",
    "        #print('[question]number of sentences: ', len(sentences_q))\n",
    "        out = []\n",
    "        #use 8 passages\n",
    "        ns = len(sentences_q)//8 #8 passages, ns sentences each passage\n",
    "        if ns==0:\n",
    "            ns = 1\n",
    "        for j in range(8):\n",
    "            p = ' '.join(s for s in sentences_q[ns*j:ns*(j+1)])\n",
    "            if j==7:\n",
    "                p += ' '.join(s for s in sentences_q[ns*(j+1):])\n",
    "            #print(j, p)\n",
    "            #out.append(use_embed([p])[0])\n",
    "            out.append(p)\n",
    "        #out = np.array(out).T\n",
    "        qss.append(out)\n",
    "        ##for answer text\n",
    "        doc_a = nlp(a)\n",
    "        sentences_a = [sent.string.strip() for sent in doc_a.sents]\n",
    "        #print('[answer]number of sentences: ', len(sentences_a))\n",
    "        out = []\n",
    "        #use 8 passages\n",
    "        ns = len(sentences_a)//8 #8 passages, ns sentences each passage\n",
    "        if ns==0:\n",
    "            ns = 1\n",
    "        for j in range(8):\n",
    "            p = ' '.join(s for s in sentences_a[ns*j:ns*(j+1)])\n",
    "            if j==7:\n",
    "                p += ' '.join(s for s in sentences_a[ns*(j+1):])\n",
    "            #print(j, p)\n",
    "            #out.append(use_embed([p])[0])\n",
    "            out.append(p)\n",
    "        #out = np.array(out).T\n",
    "        ass.append(out)\n",
    "        \n",
    "        ##as a whole sentence\n",
    "        #qss.append([t+' '+q]) \n",
    "        #ass.append([a])\n",
    "    \n",
    "    output = [np.asarray([special_char_q, special_char_a, cap_char_q, cap_char_a, unique_words_q, unique_words_a], dtype=np.float32).T, \n",
    "              np.asarray(category_index, dtype=np.int32),\n",
    "              np.asarray(host_index, dtype=np.int32)\n",
    "             ]\n",
    "    \n",
    "    qss = np.asarray(qss, dtype=str)\n",
    "    ass = np.asarray(ass, dtype=str)\n",
    "    for i in range(8):\n",
    "        output.append(qss[:,i:i+1])\n",
    "    for i in range(8):\n",
    "        output.append(ass[:,i:i+1])\n",
    "    return output\n",
    "\n",
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.asarray(qss, dtype=str).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_embed(np.asarray(qss, dtype=str)[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create model\n",
    "\n",
    "`compute_spearmanr()` is used to compute the competition metric for the validation set\n",
    "<br><br>\n",
    "`CustomCallback()` is a class which inherits from `tf.keras.callbacks.Callback` and will compute and append validation score and validation/test predictions respectively, after each epoch.\n",
    "<br><br>\n",
    "`bert_model()` contains the actual architecture that will be used to finetune BERT to our dataset. It's simple, just taking the sequence_output of the bert_layer and pass it to an AveragePooling layer and finally to an output layer of 30 units (30 classes that we have to predict)\n",
    "<br><br>\n",
    "`train_and_predict()` this function will be run to train and obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e = tf.ones((4, 512, 768))\n",
    "\n",
    "#[e,e]\n",
    "\n",
    "#tf.keras.layers.Concatenate(axis=-1)([e,e]).shape\n",
    "\n",
    "#tf.reduce_sum([e,e], axis=0).shape\n",
    "#tf.maximum(e,e).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr_ignore_nan(trues, preds):\n",
    "    rhos = []\n",
    "    for tcol, pcol in zip(np.transpose(trues), np.transpose(preds)):\n",
    "        rhos.append(spearmanr(tcol, pcol).correlation)\n",
    "    return np.nanmean(rhos)\n",
    "\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, valid_data, test_data=None, batch_size=16, fold=None, stage2=False):\n",
    "\n",
    "        self.valid_inputs = valid_data[0]\n",
    "        self.valid_outputs = valid_data[1]\n",
    "        self.test_inputs = test_data\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.fold = fold\n",
    "        self.stage2 = stage2\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.valid_predictions = []\n",
    "        self.test_predictions = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.valid_predictions.append(\n",
    "            self.model.predict(self.valid_inputs, batch_size=self.batch_size))\n",
    "        \n",
    "        rho_val = compute_spearmanr_ignore_nan(\n",
    "            self.valid_outputs, np.average(self.valid_predictions, axis=0))\n",
    "        \n",
    "        print(\"\\nvalidation rho: %.4f\" % rho_val)\n",
    "        \n",
    "        if self.fold is not None and epoch>1:\n",
    "            if self.stage2:\n",
    "                self.model.save_weights(CKPT_SAVE_PATH+f'fold{fold}-epoch{epoch}-stage2.h5py')\n",
    "            else:\n",
    "                self.model.save_weights(CKPT_SAVE_PATH+f'fold{fold}-epoch{epoch}.h5py')\n",
    "        \n",
    "#         self.test_predictions.append(\n",
    "#             self.model.predict(self.test_inputs, batch_size=self.batch_size)\n",
    "#         )\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    results = use_embed(tf.cast(tf.squeeze(x), tf.string))\n",
    "    #print(results)\n",
    "    return tf.keras.backend.concatenate([results])\n",
    "\n",
    "def use_model():\n",
    "    \n",
    "#     qss = tf.keras.layers.Input((8,), dtype=tf.string)\n",
    "#     ass = tf.keras.layers.Input((8,), dtype=tf.string)\n",
    "#     qss_embed = use_embed(qss)\n",
    "#     ass_embed = use_embed(ass)\n",
    "    \n",
    "    qss = [tf.keras.layers.Input((1,), dtype=tf.string) for _ in range(8)]\n",
    "    ass = [tf.keras.layers.Input((1,), dtype=tf.string) for _ in range(8)]\n",
    "    #qss_embed_layer = tf.keras.layers.Lambda(UniversalEmbedding, output_shape=(1,))\n",
    "    #ass_embed_layer = tf.keras.layers.Lambda(UniversalEmbedding, output_shape=(1,))\n",
    "    use_embed_layer = tf.keras.layers.Lambda(UniversalEmbedding, output_shape=(1,))\n",
    "    qss_embed = [tf.keras.backend.expand_dims(use_embed_layer(_qss)) for _qss in qss]#[(N, 512, 1),...,]\n",
    "    ass_embed = [tf.keras.backend.expand_dims(use_embed_layer(_ass)) for _ass in ass]\n",
    "    qss_embed = tf.keras.layers.Concatenate()(qss_embed)#(N, 512, 8)\n",
    "    ass_embed = tf.keras.layers.Concatenate()(ass_embed)\n",
    "    \n",
    "    feats = tf.keras.layers.Input((6,), dtype=tf.float32)#set dim of additional numeric feats\n",
    "    category_index = tf.keras.layers.Input((1,), dtype=tf.int32)\n",
    "    host_index = tf.keras.layers.Input((1,), dtype=tf.int32)\n",
    "    \n",
    "    #q_embedding = tf.keras.layers.SpatialDropout1D(0.2)(q_embedding)\n",
    "    #a_embedding = tf.keras.layers.SpatialDropout1D(0.2)(a_embedding)\n",
    "    \n",
    "    qa_embed = tf.keras.layers.Concatenate()([qss_embed, ass_embed])\n",
    "    qa1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True, \n",
    "                                                            activation='tanh', recurrent_activation='sigmoid', \n",
    "                                                            recurrent_dropout=0, unroll=False, use_bias=False\n",
    "                                                            ))(qa_embed)\n",
    "    qa2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, \n",
    "                                                            activation='tanh', recurrent_activation='sigmoid', \n",
    "                                                            recurrent_dropout=0, unroll=False, use_bias=False\n",
    "                                                            ))(qa1)\n",
    "    \n",
    "    qa1_avgpool = tf.keras.layers.GlobalAveragePooling1D()(qa1)\n",
    "    qa2_avgpool = tf.keras.layers.GlobalAveragePooling1D()(qa2)\n",
    "    #qa_maxpool = tf.keras.layers.GlobalMaxPool1D()(qa)\n",
    "    q_avgpool = tf.keras.layers.GlobalAveragePooling1D()(qss_embed)\n",
    "    a_avgpool = tf.keras.layers.GlobalAveragePooling1D()(ass_embed)\n",
    "    \n",
    "    category_embed_layer = tf.keras.layers.Embedding(6, 8, input_length=1)\n",
    "    host_embed_layer = tf.keras.layers.Embedding(64, 8, input_length=1)\n",
    "    cat_embed = category_embed_layer(category_index)\n",
    "    host_embed = host_embed_layer(host_index)\n",
    "    cat_embed = tf.keras.layers.Flatten()(cat_embed)\n",
    "    host_embed = tf.keras.layers.Flatten()(host_embed)\n",
    "    \n",
    "    #x = tf.keras.layers.Concatenate()([q, a, feats, cat_embed, host_embed])\n",
    "    x = tf.keras.layers.Concatenate()([qa1_avgpool, qa2_avgpool, q_avgpool, a_avgpool,\n",
    "                                       feats, cat_embed, host_embed])\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(30, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[feats, category_index, host_index]+qss+ass, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_predict(model, train_data, valid_data, test_data, \n",
    "                      learning_rate, epochs, batch_size, loss_function, fold, stage2=False):\n",
    "    \"\"\"\n",
    "    multipliers = {'dense_1': 0.5, 'dense_2': 0.4}\n",
    "    optimizer = LearningRateMultiplier(tf.keras.optimizers.Adam, \n",
    "                                        lr_multiplier=multipliers, learning_rate=learning_rate)\n",
    "    \n",
    "    \"\"\"\n",
    "    custom_callback = CustomCallback(\n",
    "        valid_data=(valid_data[0], valid_data[1]), \n",
    "        test_data=test_data,\n",
    "        batch_size=batch_size,\n",
    "        fold=fold, stage2=stage2)\n",
    "\n",
    "    #decay_steps = 1000\n",
    "    #lr_decayed_fn = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "    #clr = CyclicLR(base_lr=2e-5, max_lr=5e-5, step_size=2000., mode='triangular')\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)#clipvalue=0.5\n",
    "    model.compile(loss=loss_function, optimizer=optimizer)\n",
    "    model.fit(train_data[0], train_data[1], epochs=epochs, \n",
    "              batch_size=batch_size, callbacks=[custom_callback])\n",
    "    \n",
    "    return custom_callback\n",
    "\n",
    "def predict(model, test_data, load_weights_path):\n",
    "    model.load_weights(load_weights_path)\n",
    "    return model.predict(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_77 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_79 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_83 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_85 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_86 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_87 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_88 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_89 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_91 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 512)          0           input_76[0][0]                   \n",
      "                                                                 input_77[0][0]                   \n",
      "                                                                 input_78[0][0]                   \n",
      "                                                                 input_79[0][0]                   \n",
      "                                                                 input_80[0][0]                   \n",
      "                                                                 input_81[0][0]                   \n",
      "                                                                 input_82[0][0]                   \n",
      "                                                                 input_83[0][0]                   \n",
      "                                                                 input_84[0][0]                   \n",
      "                                                                 input_85[0][0]                   \n",
      "                                                                 input_86[0][0]                   \n",
      "                                                                 input_87[0][0]                   \n",
      "                                                                 input_88[0][0]                   \n",
      "                                                                 input_89[0][0]                   \n",
      "                                                                 input_90[0][0]                   \n",
      "                                                                 input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_48 (Tens [(None, 512, 1)]     0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_49 (Tens [(None, 512, 1)]     0           lambda_6[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_50 (Tens [(None, 512, 1)]     0           lambda_6[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_51 (Tens [(None, 512, 1)]     0           lambda_6[3][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_52 (Tens [(None, 512, 1)]     0           lambda_6[4][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_53 (Tens [(None, 512, 1)]     0           lambda_6[5][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_54 (Tens [(None, 512, 1)]     0           lambda_6[6][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_55 (Tens [(None, 512, 1)]     0           lambda_6[7][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_56 (Tens [(None, 512, 1)]     0           lambda_6[8][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_57 (Tens [(None, 512, 1)]     0           lambda_6[9][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_58 (Tens [(None, 512, 1)]     0           lambda_6[10][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_59 (Tens [(None, 512, 1)]     0           lambda_6[11][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_60 (Tens [(None, 512, 1)]     0           lambda_6[12][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_61 (Tens [(None, 512, 1)]     0           lambda_6[13][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_62 (Tens [(None, 512, 1)]     0           lambda_6[14][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_63 (Tens [(None, 512, 1)]     0           lambda_6[15][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 512, 8)       0           tf_op_layer_ExpandDims_48[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_49[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_50[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_51[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_52[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_53[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_54[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 512, 8)       0           tf_op_layer_ExpandDims_56[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_57[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_58[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_59[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_60[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_61[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_62[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 512, 16)      0           concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 512, 64)      12288       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_93 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_94 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 512, 64)      18432       bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 8)         48          input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 8)         512         input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 64)           0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 64)           0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 8)            0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 8)            0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_92 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 8)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 8)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 166)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "                                                                 global_average_pooling1d_14[0][0]\n",
      "                                                                 global_average_pooling1d_15[0][0]\n",
      "                                                                 input_92[0][0]                   \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 166)          0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           5010        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 36,290\n",
      "Trainable params: 36,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = use_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs[10].shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Obtain inputs and targets, as well as the indices of the train/validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c3deeceb284f329f18e9b965679db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2347 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2152 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1985 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1396 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1460 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3335 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1901 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2686 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2009 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1752 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1584 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (9317 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2411 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2768 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2264 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1200 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2674 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3026 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1941 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3148 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1901 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2152 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2982 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2411 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3001 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1366 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2035 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2683 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3335 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2347 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2399 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2818 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2819 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2615 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2143 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2781 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2179 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2781 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1653 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1128 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2077 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3200 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1877 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1516 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2185 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2494 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1302 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1287 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6789 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3081 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1828 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1742 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1442 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2035 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4767 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1660 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (880 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1714 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2077 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2818 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1332 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1763 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3595 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2601 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1428 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2012 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2136 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2942 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2063 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1772 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1787 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3595 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1667 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (6789 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2494 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2546 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1602 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1550 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1830 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2365 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3060 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1521 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (4390 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2114 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1942 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1094 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3060 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3081 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_PREDICT == 'train':\n",
    "    outputs = compute_output_arrays(df_train, output_categories)\n",
    "    inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load gkf\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "if TRAIN_PREDICT == 'train':\n",
    "    if not os.path.isfile('../data/gkf%d.pkl'%SEED):\n",
    "        print('Create gkf')\n",
    "        gkf = GroupKFold(n_splits=5).split(X=df_train.question_body, groups=df_train.question_body)\n",
    "        with open('../data/gkf%d.pkl'%SEED, 'wb') as f:\n",
    "            pickle.dump(list(gkf), f)\n",
    "    else:\n",
    "        print('Load gkf')\n",
    "        with open('../data/gkf%d.pkl'%SEED, 'rb') as f:\n",
    "            gkf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(inputs), inputs[6].shape, inputs[7], inputs[8])\n",
    "#inputs[6][:,4:]\n",
    "# for i,(train_idx,val_idx) in enumerate(gkf):\n",
    "#     if i==0:\n",
    "#         break\n",
    "# train_idx[20:30]\n",
    "#inputs[8][0].shape\n",
    "\n",
    "#gkf0 = list(gkf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 5 epochs --- with a learning rate of 1e-5 and batch_size of 8. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 4\n",
    "BATCH_SIZE = 8\n",
    "LearningRate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_bce_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    nunique = [df_train[col].nunique() for col in output_categories]#count unique values of each column\n",
    "    weights_dict = {5:0.5, 9:1.0, 17:1.5, 3:0.5}\n",
    "    weights = [weights_dict[i] for i in nunique]\n",
    "    \"\"\"\n",
    "    weights = tf.convert_to_tensor([1. , 1. , 0.5, 0.5, 0.5, 0.5, 1. , 1. , 0.5, 0.5, 0.5, 0.5, 0.5,\n",
    "       0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1. , 1. , 1. , 1. , 1. , 1.5,\n",
    "       0.5, 0.5, 0.5, 1. ], dtype=float)\n",
    "    weights = weights/K.mean(weights)\n",
    "    loss = tf.multiply(y_true, K.log(y_pred+K.epsilon())) + tf.multiply((1-y_true), K.log(1-y_pred+K.epsilon()))\n",
    "    loss = tf.multiply(loss, weights)\n",
    "    bce_loss = tf.reduce_mean(-loss)\n",
    "    return bce_loss\n",
    "#     y_true_clip = K.clip(y_true, K.epsilon(), 1)\n",
    "#     y_pred_clip = K.clip(y_pred, K.epsilon(), 1)\n",
    "#     kl_loss = tf.reduce_mean(tf.reduce_sum(y_true_clip * K.log(y_true_clip / y_pred_clip), axis=0))\n",
    "#     return bce_loss*0.9 + kl_loss*0.1\n",
    "\n",
    "#y_pred = tf.random.uniform((8, 30))\n",
    "#y_true = tf.random.uniform((8, 30))\n",
    "\n",
    "#custom_bce_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training fold 0========\n",
      "Train on 4863 samples\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4856/4863 [============================>.] - ETA: 3s - loss: 0.4054\n",
      "validation rho: 0.3786\n",
      "4863/4863 [==============================] - 2687s 553ms/sample - loss: 0.4054\n",
      "Epoch 2/4\n",
      "4856/4863 [============================>.] - ETA: 2s - loss: 0.3812\n",
      "validation rho: 0.3994\n",
      "4863/4863 [==============================] - 2216s 456ms/sample - loss: 0.3812\n",
      "Epoch 3/4\n",
      "4856/4863 [============================>.] - ETA: 2s - loss: 0.3688\n",
      "validation rho: 0.4065\n",
      "4863/4863 [==============================] - 2225s 457ms/sample - loss: 0.3688\n",
      "Epoch 4/4\n",
      "4856/4863 [============================>.] - ETA: 2s - loss: 0.3573\n",
      "validation rho: 0.4081\n",
      "4863/4863 [==============================] - 2219s 456ms/sample - loss: 0.3573\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "## if stage2, modify 2 places\n",
    "if TRAIN_PREDICT == 'train':\n",
    "    histories = []\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "\n",
    "        # will actually only do 1 fold (out of 5) to compare models\n",
    "        if fold ==0:\n",
    "            print('========training fold %d========'%fold)\n",
    "            K.clear_session()\n",
    "            \n",
    "            model = bert_model()\n",
    "            \n",
    "            #prepare dataset\n",
    "            train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
    "            train_outputs = outputs[train_idx]\n",
    "            valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
    "            valid_outputs = outputs[valid_idx]\n",
    "\n",
    "            # history contains two lists of valid and test preds respectively:\n",
    "            #  [valid_predictions_{fold}, test_predictions_{fold}]\n",
    "            history = train_and_predict(model, \n",
    "                              train_data=(train_inputs, train_outputs), \n",
    "                              valid_data=(valid_inputs, valid_outputs),\n",
    "                              test_data=None, \n",
    "                              learning_rate=LearningRate, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                              loss_function=custom_bce_loss, fold=fold, \n",
    "                                        stage2=False)#'binary_crossentropy'\n",
    "            histories.append(history)\n",
    "\n",
    "# ## training full trainset to lift LB score in the final\n",
    "# if TRAIN_PREDICT == 'train':\n",
    "#     histories = []\n",
    "#     print('========Start training========')\n",
    "#     K.clear_session()\n",
    "#     model = bert_model()\n",
    "\n",
    "#     train_inputs = inputs\n",
    "#     train_outputs = outputs\n",
    "\n",
    "#     history = train_and_predict(model, \n",
    "#                       train_data=(train_inputs, train_outputs), \n",
    "#                       valid_data=None,\n",
    "#                       test_data=None, \n",
    "#                       learning_rate=LearningRate, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "#                       loss_function='binary_crossentropy', fold=fold)\n",
    "\n",
    "#     histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more ideas todo: \n",
    "#1.1 modify model\n",
    "    #sliding window for sentences --> USE embed --> LSTM\n",
    "    #https://github.com/google-research/bert/issues/66\n",
    "    #https://www.kaggle.com/c/google-quest-challenge/discussion/120185#689854\n",
    "#post-process, transform prediction to rank, to get averaged rank across folds, then assign new predictions\n",
    "#1.2 OOV words spelling correction\n",
    "#1.3 train >4 epochs\n",
    "#2. loss, ranking loss?\n",
    "#3. add custom new tokens?(e.g stackoverflow)\n",
    "#4. roberta?alxnet?\n",
    "#5. RankGauss average folds?\n",
    "#6. freeze some layers of bert?\n",
    "\"\"\"\n",
    "CV history\n",
    "---------------\n",
    "#### bert-base ####\n",
    "Epoch 5/15\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3091\n",
    "validation rho: 0.3923\n",
    "4863/4863 [==============================] - 339s 70ms/sample - loss: 0.3091\n",
    "------LB=0.346\n",
    "\n",
    "switch to HuggingFace\n",
    "----------------------\n",
    "SEEMS DEPENDS ON THE SEED!!!\n",
    "----------------------------\n",
    "t + q[:1/2], q[1/2:], a\n",
    "same\n",
    "\n",
    "category + host + t + q, category + host + a\n",
    "same\n",
    "\n",
    "\n",
    "CUSTOM LOSS\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3612\n",
    "validation rho: 0.3989\n",
    "4863/4863 [==============================] - 711s 146ms/sample - loss: 0.3612\n",
    "\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3597\n",
    "validation rho: 0.3998\n",
    "4863/4863 [==============================] - 724s 149ms/sample - loss: 0.3597\n",
    "\n",
    "add 2 feats\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3616\n",
    "validation rho: 0.4049\n",
    "4863/4863 [==============================] - 718s 148ms/sample - loss: 0.3616\n",
    "\n",
    "4 feats\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3592\n",
    "validation rho: 0.4027\n",
    "4863/4863 [==============================] - 706s 145ms/sample - loss: 0.3591\n",
    "\n",
    "add cat+host embed dim=16\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3594\n",
    "validation rho: 0.4005\n",
    "4863/4863 [==============================] - 698s 144ms/sample - loss: 0.3594\n",
    "\n",
    "embed dim=8\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 0s - loss: 0.3592\n",
    "validation rho: 0.4071\n",
    "4863/4863 [==============================] - 734s 151ms/sample - loss: 0.3592\n",
    "\n",
    "add LSTM features\n",
    "validation rho: 0.4081 --fold0\n",
    "validation rho: 0.4050 --fold1\n",
    "validation rho: 0.4138 --fold2\n",
    "validation rho: 0.4018 --fold3\n",
    "validation rho: 0.3982 --fold4\n",
    "LB=0.388, CV=0.405\n",
    "\n",
    "CV 0.397 to 0.405, LB 0.387 to 0.388 ???\n",
    "\n",
    "\n",
    "add t+[SPECIAL TOKEN]+q\n",
    "validation rho: 0.4113 --fold0\n",
    "validation rho: 0.4014 --fold1\n",
    "validation rho: 0.4224 --fold2\n",
    "validation rho: 0.4055 --fold3\n",
    "validation rho: 0.3961 --fold4\n",
    "CV=0.407, LB=0.387\n",
    "\n",
    "--------\n",
    "epochs progression:\n",
    "\n",
    "4856/4863 [============================>.] - ETA: 2s - loss: 0.4053\n",
    "validation rho: 0.3832\n",
    "4863/4863 [==============================] - 2045s 421ms/sample - loss: 0.4052\n",
    "Epoch 2/4\n",
    "4856/4863 [============================>.] - ETA: 2s - loss: 0.3799\n",
    "validation rho: 0.4016\n",
    "4863/4863 [==============================] - 1995s 410ms/sample - loss: 0.3799\n",
    "Epoch 3/4\n",
    "4856/4863 [============================>.] - ETA: 2s - loss: 0.3680\n",
    "validation rho: 0.4092\n",
    "4863/4863 [==============================] - 2002s 412ms/sample - loss: 0.3680\n",
    "Epoch 4/4\n",
    "4856/4863 [============================>.] - ETA: 2s - loss: 0.3557\n",
    "validation rho: 0.4108\n",
    "4863/4863 [==============================] - 1998s 411ms/sample - loss: 0.3557\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Process and submit test predictions\n",
    "\n",
    "First the test predictions are read from the list of lists of `histories`. Then each test prediction list (in lists) is averaged. Then a mean of the averages is computed to get a single prediction for each data point. Finally, this is saved to `submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_input_arays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f9adc5d53dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN_PREDICT\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_input_arays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_input_arays' is not defined"
     ]
    }
   ],
   "source": [
    "if TRAIN_PREDICT == 'predict':\n",
    "    \n",
    "    test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    model = bert_model()\n",
    "    \n",
    "    test_predictions = [predict(model, test_inputs, load_weights_path=ckpt_load_path) \n",
    "                        for ckpt_load_path in CKPT_LOAD_PATH]\n",
    "    #test_predictions = [np.average(test_predictions[i], axis=0) for i in range(len(test_predictions))]\n",
    "    test_predictions = np.mean(test_predictions, axis=0)\n",
    "\n",
    "    df_sub.iloc[:, 1:] = test_predictions\n",
    "\n",
    "    df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##post process\n",
    "# cols2process = df_train.columns.tolist()[11:]\n",
    "# print(len(cols2process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in tqdm(cols2process):\n",
    "#     ###step1\n",
    "#     quantiles = df_train[col].value_counts()/len(df_train.index)\n",
    "#     quantiles = quantiles.to_dict()\n",
    "#     quantiles = {k: v for k, v in sorted(quantiles.items(), key=lambda item: item[0])}\n",
    "#     ks = list(quantiles.keys())\n",
    "#     vs = list(quantiles.values())\n",
    "#     qs = np.cumsum(vs)\n",
    "#     #print(ks)\n",
    "#     #print(qs)\n",
    "#     ###step2\n",
    "#     qs = np.quantile(df_sub[col], qs)\n",
    "#     #print(qs)\n",
    "#     for i in range(len(qs)):\n",
    "#         if i==0:\n",
    "#             q = qs[0]\n",
    "#             df_sub.loc[df_sub[col]<q, col] = ks[i]\n",
    "#         elif i>0 and i<=len(qs)-1:\n",
    "#             q0,q1 = qs[i-1], qs[i]\n",
    "#             df_sub.loc[(df_sub[col]<q1)&(df_sub[col]>=q0), col] = ks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maybe post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho_val:  0.39507176135825195\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "    #prepare dataset\n",
    "    train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
    "    train_outputs = outputs[train_idx]\n",
    "    valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
    "    valid_outputs = outputs[valid_idx]\n",
    "\n",
    "#     model.load_weights('../checkpoint/bert-base-uncased-v3/fold0-epoch3.h5py')\n",
    "#     valid_predictions0 = model.predict(valid_inputs, batch_size=BATCH_SIZE)\n",
    "#     rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_predictions0)\n",
    "#     print('rho_val: ', rho_val)\n",
    "    \n",
    "    model.load_weights('../checkpoint/bert-base-uncased-v4/fold0-epoch3.h5py')\n",
    "    valid_predictions1 = model.predict(valid_inputs, batch_size=BATCH_SIZE)\n",
    "    rho_val = compute_spearmanr_ignore_nan(valid_outputs, valid_predictions1)\n",
    "    print('rho_val: ', rho_val)\n",
    "    \n",
    "    if fold==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [valid_predictions, valid_predictions1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "cols = range(30)#[0]\n",
    "\n",
    "def rank_average(cols):\n",
    "    preds_avg = np.empty_like(preds[0])\n",
    "    for col in cols:\n",
    "        avg_rank = np.mean([rankdata(p[:,col], method='dense') for p in preds], axis=0).round(0).astype(int)\n",
    "        avg_rank = rankdata(avg_rank, method='dense')-1\n",
    "        nunique = np.unique(avg_rank).shape[0]\n",
    "        arrays = np.array([p[:,col] for p in preds])\n",
    "        ranges = arrays.min(), arrays.max()\n",
    "        uniform = np.linspace(ranges[0],ranges[1],nunique)\n",
    "        refined = np.array([uniform[i] for i in avg_rank])\n",
    "        preds_avg[:,col] = refined\n",
    "    return preds_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined = rank_average(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4036110465409228"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho_val = compute_spearmanr_ignore_nan(valid_outputs, refined)\n",
    "rho_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bc299fd86004a25b80d81e6b2cf26c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e9dee551491d4948a03903a599ac071c",
        "IPY_MODEL_10d886fb72ca42ffb05a285d9fe30778"
       ],
       "layout": "IPY_MODEL_f0e52773a0d04a45aff825ab31f41876"
      }
     },
     "10d886fb72ca42ffb05a285d9fe30778": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_828d99d02c3b49bb93d6b047fbd09fc9",
       "placeholder": "",
       "style": "IPY_MODEL_8e4ceb4264364e6e8d60c97ad0f9743c",
       "value": " 476/? [00:06&lt;00:00, 70.36it/s]"
      }
     },
     "5e63ae9931c4486bace382463a33cb9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dffd11c5be394b618b38f578a36ec632",
       "placeholder": "",
       "style": "IPY_MODEL_8c1507e9b0ae4473b10411aee0dfe8b3",
       "value": " 6079/? [01:13&lt;00:00, 82.70it/s]"
      }
     },
     "692354900b5945b18317e1f0bb9e093e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2f601ced3704df3b1c307077b9edfc4",
        "IPY_MODEL_5e63ae9931c4486bace382463a33cb9f"
       ],
       "layout": "IPY_MODEL_c597b499528d4584bc987338e2bdac86"
      }
     },
     "744b082507e449338929068fb9370102": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "828d99d02c3b49bb93d6b047fbd09fc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c1507e9b0ae4473b10411aee0dfe8b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8e4ceb4264364e6e8d60c97ad0f9743c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8f4d97d1646544329131d55a1d70da5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "92f22ae1f0bb48ef8c83a703dee02794": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c597b499528d4584bc987338e2bdac86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c89074dd61cb451aaf79502e1b3f0006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "dffd11c5be394b618b38f578a36ec632": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2f601ced3704df3b1c307077b9edfc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f4d97d1646544329131d55a1d70da5b",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c89074dd61cb451aaf79502e1b3f0006",
       "value": 1
      }
     },
     "e9dee551491d4948a03903a599ac071c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_744b082507e449338929068fb9370102",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_92f22ae1f0bb48ef8c83a703dee02794",
       "value": 1
      }
     },
     "f0e52773a0d04a45aff825ab31f41876": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
